# WordSeqenceDecoding
This notebook trains a seq2seq decoder model with teacher forcing. Then use the trained layers from the decoder to generate a sentence.
The dataset is a bunch of Sonnets,a fourteen-line poem written in iambic pentameter. So 14 lines of sentence will be our output at a time.
